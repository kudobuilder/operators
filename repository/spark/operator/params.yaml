apiVersion: kudo.dev/v1beta1
parameters:
  # Service Accounts and RBAC
  - name: operatorServiceAccountName
    description: "Service Account for Spark Operator"
    default: "spark-operator-service-account"
    displayName: "Operator Service Account"

  - name: createOperatorServiceAccount
    description: "Automatically create Service Account for Spark Operator"
    default: true
    displayName: "Auto Create Operator Service Account"

  - name: sparkServiceAccountName
    description: "Use Service Account for Spark Drivers"
    default: "spark-service-account"
    displayName: "Spark Drivers Service Account"

  - name: createSparkServiceAccount
    description: "Automatically generate Service Account for Spark Drivers"
    default: true
    displayName: "Auto Create Service Account for Spark Drivers"

  - name: createRBAC
    description: "Automatically create RBAC for Spark Operator and Drivers"
    default: true
    displayName: "Auto Create RBAC for Spark Operator and Drivers"

  # Docker image
  - name: operatorImageName
    description: "Operator Docker image name"
    default: mesosphere/kudo-spark-operator
    displayName: "Operator Docker image name"

  - name: operatorVersion
    description: "Operator Docker image version (tag)"
    default: 3.0.0-1.1.0
    displayName: "Operator Docker image version (tag)"

  - name: imagePullPolicy
    description: "Image pull policy"
    default: Always
    displayName: "Image pull policy"

  ## Metrics
  - name: enableMetrics
    description: "Enable metrics"
    default: false
    displayName: "Enable metrics"

  - name: operatorMetricsPort
    description: "Spark Operator Metrics port"
    default: 10254
    displayName: "Spark Operator Metrics port"

  - name: appMetricsPort
    desription: "The port the JMX exporter Java agent binds to for driver/executor pods"
    default: 8090
    displayName: "Spark Application Metrics port"

  - name: metricsPollingInterval
    description: "Interval at which metrics should be scraped"
    default: "5s"
    displayName: "Metrics polling interval"

  - name: metricsEndpoint
    description: "Metrics endpoint"
    default: "/metrics"
    displayName: "Metrics endpoint"

  - name: metricsPrefix
    description: "Metrics prefix"
    default: ""
    displayName: "Metrics prefix"

  - name: resyncIntervalSeconds
    description: "Informer resync interval in seconds"
    default: 30
    displayName: "Informer resync interval in seconds"

  # History Server
  - name: enableHistoryServer
    description: "Start Spark History Server"
    default: false
    displayName: "Enable Spark History Server"

  - name: historyServerFsLogDirectory
    description: "Spark EventLog Directory from which to load events for prior Spark job runs (e.g., hdfs://hdfs/ or s3a://path/to/bucket). Note: You'd typically want to set this to point to distributed/HA storage"
    default: ""
    displayName: "Spark History Server Event Log Directory"

  - name: historyServerCleanerEnabled
    description: "Specifies whether the Spark History Server should periodically clean up event logs from storage."
    default: "false"
    displayName: "Spark History Server Cleaner Enabled"

  - name: historyServerCleanerInterval
    description: "Frequency the Spark History Server checks for files to delete."
    default: "1d"
    displayName: "Spark History Server Cleaner Interval"

  - name: historyServerCleanerMaxAge
    description: "History files older than this will be deleted."
    default: "7d"
    displayName: "Spark History Server Cleaner Max Age"

  - name: historyServerOpts
    description: "Extra options to pass to the Spark History Server"
    default: ""
    displayName: "Spark History Server Options"

  - name: historyServerPVCName
    description: "External Persistent Volume Claim Name used for Spark event logs storage by History Server"
    default: ""
    displayName: "Spark History Server Persistent Volume Claim Name"

  - name: historyServerSparkConfSecret
    description: "Name of a Secret with Spark config file. The secret should be in the same namespace as the Operator."
    default: ""
    displayName: "Name of a Secret with Spark History Server configuration file"

  - name: delegationTokenSecret
    description: "Name of a Secret with Hadoop Delegation Token. The secret should be in the same namespace as the Operator."
    default: ""
    displayName: "Name of a Secret with Hadoop Delegation Token"

  ## Miscellaneous
  - name: sparkJobNamespace
    description: "Namespace for Spark Applications. By default, Spark Operator will monitor Spark Application across all the namespaces."
    default: ""
    displayName: "Namespace for Spark Applications"

  - name: enableWebhook
    description: "Enable webhook"
    default: true
    displayName: "Enable webhook"

  - name: webhookPort
    description: "Webhook port"
    default: 8080
    displayName: "Webhook port"

  - name: controllerThreads
    description: "Controller threads"
    default: 10
    displayName: "Controller threads"

  - name: ingressUrlFormat
    description: "Ingress URL format"
    default: ""
    displayName: "Ingress URL format"

  ## Output verbosity and debugging level
  ## Ref: https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-output-verbosity-and-debugging
  - name: logLevel
    description: "Log Level"
    default: 2
    displayName: "Log Level"

  ## Whether to enable batch scheduler for pod scheduling,
  ## if enabled, end user can specify batch scheduler name in spark application.
  - name: enableBatchScheduler
    description: "Enable Batch Scheduler"
    default: false
    displayName: "Enable Batch Scheduler"

  - name: installCrds
    description: "Install sparkapplications.sparkoperator.k8s.io and scheduledsparkapplications.sparkoperator.k8s.io"
    default: true
    displayName: "Install Spark Operator CRDs"

  - name: replicas
    description: "The number of replicas of the operator Deployment"
    default: 1
    displayName: "Number of replicas"

  - name: enableLeaderElection
    description: "Whether to enable leader election when the operator Deployment has more than one replica, i.e., when replicas is greater than 1."
    default: false
    displayName: "Enable leader election"

  - name: leaderElectionLockName
    description: "Name of the lock resource (ConfigMap) used for leader election"
    default: spark-operator-lock
    displayName: "Name of the lock resource"

  - name: leaderElectionLockNamespace
    description: "Namespace of the lock resource used for leader election. Defaults to Operator namespace"
    default: ""
    displayName: "Lock resource namespace"

  - name: leaderElectionLeaseDuration
    description: "Leader election lease duration."
    default: 15s
    displayName: "Leader election lease duration"

  - name: leaderElectionRenewDeadline
    description: "Leader election renew deadline."
    default: 14s
    displayName: "Leader election renew deadline"

  - name: leaderElectionRetryPeriod
    description: "Leader election retry period."
    default: 4s
    displayName: "Leader election retry period"
