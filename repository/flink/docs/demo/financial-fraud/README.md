# Flink Financial Fraud Demo

This demo follows the outline provided by [DCOS's](https://github.com/dcos/demos/tree/master/flink-k8s/1.11) demo

### Architecture

![Financial transaction processing demo architecture](https://github.com/dcos/demos/raw/master/flink-k8s/1.11/img/kafka-flink-arch.png)

This demo implements a data processing infrastructure with KUDO that is able to spot money laundering. In the context of money laundering, we  want to detect amounts larger than $10.000 transferred between two accounts, even if that amount is split into many small batches.  See also [US](https://www.fincen.gov/history-anti-money-laundering-laws) and [EU](http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32015L0849) legislation and regulations on this topic for more information.

The architecture follows more or less the [SMACK stack architecture](https://mesosphere.com/blog/smack-stack-new-lamp-stack/):
- Events: Event are being generated by a small [Golang generator](https://github.com/dcos/demos/blob/master/flink/1.11/generator/generator.go). The events are in the form 'Sunday, 23-Jul-17 01:06:47 UTC;66;26;7810', where the first field '23-Jul-17 01:06:47 UTC' represents the (increasing) timestamp of transactions; the second field '66' represent the sender account; the third field the receiver account; and the fourth field represent the dollar amount transferred during that transaction.
- Ingestion: The generated events are being ingested and buffered by a Kafka queue with the default topic 'transactions'. Being a Microservice we will deploy the data-generator on kubernetes.
- Stream Processing: As we require fast response times, we use Apache Flink as a Stream processor running the [FinancialTransactionJob](https://github.com/dcos/demos/tree/master/flink/1.10/flink-job/src/main/java/io/dcos).
- Storage: Here we diverge a bit from the typical SMACK stack setup and don't write the results into a Datastore such as Apache Cassandra. Instead we write the results again into a Kafka Stream (default: 'fraud'). Note, that Kafka also offers data persistence for all unprocessed events.
- Actor: In order to view the results we use again a small [Golang viewer](https://github.com/dcos/demos/blob/master/flink/1.11/actor/actor_viewer.go) which simply reads and displays the results from the output Kafka stream. Being a Microservice we will deploy the viewer on kubernetes.

## Prerequisites

Before you get started:

- Make sure you have a cluster at hand with enough resources, e.g.:

```.
minikube start --vm-driver=hyperkit --cpus=6 --memory=9216 --disk-size=10g
```

- Have current KUDO `v0.3.x` or higher installed on your cluster:
    - If you have KUDO already installed to the `kudo-system` namespace check its current Docker image tag to verify the version you are running:
        - Make sure the output of `kubectl get pod kudo-controller-manager-0 -n kudo-system -o jsonpath='{.spec.containers[0].image}'` shows at least `v0.3.3` as Docker tag:
        ```bash
        $ kubectl get pod kudo-controller-manager-0 -n kudo-system -o jsonpath='{.spec.containers[0].image}'
        kudobuilder/controller:v0.3.3
        ```
    - If not, use the following commands to install KUDO `v0.3.3` to your cluster:
        - `kubectl create -f https://raw.githubusercontent.com/kudobuilder/kudo/v0.3.3/docs/deployment/00-prereqs.yaml`
        - `kubectl create -f https://raw.githubusercontent.com/kudobuilder/kudo/v0.3.3/docs/deployment/10-crds.yaml`
        - `kubectl create -f https://raw.githubusercontent.com/kudobuilder/kudo/v0.3.3/docs/deployment/20-deployment.yaml`
- Have current KUDO CLI `v0.3.x` or higher [installed](https://kudo.dev/docs/cli/#install)
    - Run `kubectl kudo version`, the output should look like:
    ```bash
    KUDO Version: version.Info{GitVersion:"0.3.3", GitCommit:"fc29a79f", BuildDate:"2019-07-22T15:21:32Z", GoVersion:"go1.12.5", Compiler:"gc", Platform:"darwin/amd64"}
    ```
    - If not, upgrade to the latest version via `brew upgrade kudo-cli`
- Have the `zookeeper` Operator with `0.1.0` as OperatorVersion installed
    - Use the KUDO CLI with the following command:
        ```bash
        $ kubectl kudo install zookeeper --version=0.1.0 --skip-instance
        operator.kudo.k8s.io/v1alpha1/zookeeper created
        operatorversion.kudo.k8s.io/v1alpha1/zookeeper-0.1.0 created
        ```
- Have the `kafka` Operator with `0.1.1` as OperatorVersion installed
    - Use the KUDO CLI with the following command:
        ```bash
        $ kubectl kudo install kafka --version=0.1.1 --skip-instance
        operator.kudo.k8s.io/v1alpha1/kafka created
        operatorversion.kudo.k8s.io/v1alpha1/kafka-0.1.1 created
        ```
- Have the `flink` Operator with `0.1.0` as OperatorVersion installed
    - Use the KUDO CLI with the following command:
        ```bash
        $ kubectl kudo install flink --version=0.1.0 --skip-instance
        operator.kudo.k8s.io/v1alpha1/flink created
        operatorversion.kudo.k8s.io/v1alpha1/flink-0.1.0 created
        ```

Now you should have all required Operators installed.

## Getting Started

Install the Flink `financial-fraud` demo from the main repository directory.

 - Get the KUDO Operators repository: `git clone git@github.com:kudobuilder/operators.git`
    - Change directory into the cloned repository: `cd operators`
    - Install the Flink demo objects straight out of the repository:
        ```bash
        $ kubectl kudo install repository/flink/docs/demo/financial-fraud/demo-operator --instance flink-demo
        operator.kudo.k8s.io/v1alpha1/flink-demo created
        operatorversion.kudo.k8s.io/v1alpha1/flink-demo-0.1.0 created
        No instance named 'flink-demo' tied to this 'flink-demo' version has been found. Do you want to create one? (Yes/no) yes
        instance.kudo.k8s.io/v1alpha1/flink-demo created
        ```

To see the status of the deploy plan for the Zookeeper operator we can utilize the CLI via:

```bash

$ kubectl kudo plan status --instance flink-demo-zk
Plan(s) for "flink-demo-zk" in namespace "default":
.
└── flink-demo-zk (Operator-Version: "zookeeper-0.1.0" Active-Plan: "flink-demo-zk-deploy-704671932")
    ├── Plan deploy (serial strategy) [IN_PROGRESS]
    │   ├── Phase zookeeper (parallel strategy) [IN_PROGRESS]
    │   │   └── Step everything (IN_PROGRESS)
    │   └── Phase validation (parallel strategy) [PENDING]
    │       └── Step validation ()
    └── Plan validation (serial strategy) [NOT ACTIVE]
        └── Phase connection (parallel strategy) [NOT ACTIVE]
            └── Step connection (parallel strategy) [NOT ACTIVE]
                └── connection [NOT ACTIVE]


```

If the Zookeeper Operator was successfully installed its plan status will show `COMPLETE`:

```
$ kubectl kudo plan status --instance flink-demo-zk
Plan(s) for "flink-demo-zk" in namespace "default":
.
└── flink-demo-zk (Operator-Version: "zookeeper-0.1.0" Active-Plan: "flink-demo-zk-deploy-704671932")
    ├── Plan deploy (serial strategy) [COMPLETE]
    │   ├── Phase zookeeper (parallel strategy) [COMPLETE]
    │   │   └── Step everything (COMPLETE)
    │   └── Phase validation (parallel strategy) [COMPLETE]
    │       └── Step validation (COMPLETE)
    └── Plan validation (serial strategy) [NOT ACTIVE]
        └── Phase connection (parallel strategy) [NOT ACTIVE]
            └── Step connection (parallel strategy) [NOT ACTIVE]
                └── connection [NOT ACTIVE]
```

Next, the Kafka operator will start its `deploy` plan, when completed we will see its status change to `COMPLETE` as well:

```
$ kubectl kudo plan status --instance flink-demo-kafka
Plan(s) for "flink-demo-kafka" in namespace "default":
.
└── flink-demo-kafka (Operator-Version: "kafka-0.1.1" Active-Plan: "flink-demo-kafka-deploy-11918518")
    └── Plan deploy (serial strategy) [COMPLETE]
        └── Phase deploy-kafka (serial strategy) [COMPLETE]
            └── Step deploy (COMPLETE)

```

Lastly, the Flink operator needs to be installed. We wait for its status to be completed similar to Zookeeper and Kafka:

```
$ kubectl kudo plan status --instance flink-demo-flink
Plan(s) for "flink-demo-flink" in namespace "default":
.
└── flink-demo-flink (Operator-Version: "flink-0.1.0" Active-Plan: "flink-demo-flink-deploy-520884487")
    └── Plan deploy (serial strategy) [COMPLETE]
        └── Phase flink (serial strategy) [COMPLETE]
            └── Step jobmanager (COMPLETE)
```

Now, if we look at the overall Flink-Demo Operator status we see the combined status of all plans and phases run for the
Flink demo:

```
$ kubectl kudo plan status --instance flink-demo
Plan(s) for "flink-demo" in namespace "default":
.
└── flink-demo (Operator-Version: "flink-demo-0.1.0" Active-Plan: "flink-demo-deploy-144875020")
    └── Plan deploy (serial strategy) [COMPLETE]
        ├── Phase dependencies (serial strategy) [COMPLETE]
        │   ├── Step zookeeper (COMPLETE)
        │   └── Step kafka (COMPLETE)
        ├── Phase flink-cluster (serial strategy) [COMPLETE]
        │   └── Step flink (COMPLETE)
        ├── Phase demo (serial strategy) [COMPLETE]
        │   ├── Step gen (COMPLETE)
        │   └── Step act (COMPLETE)
        └── Phase flink-job (serial strategy) [COMPLETE]
            └── Step submit (COMPLETE)
```

Wonderful, all phases completed and our Flink job even got submitted. In order to verify it is running, let's have a look
at the Flink dashboard:

- Run `kubectl proxy` to make the dashboard available
- Access in your web-browser: http://127.0.0.1:8001/api/v1/namespaces/default/services/flink-demo-flink-jobmanager:ui/proxy/#/overview

### Flink Job Output

To see if the job was submitted successfully:

```bash
$ kubectl logs $(kubectl get pod -l job-name=flink-demo-submit-flink-job -o jsonpath="{.items[0].metadata.name}")
DOWNLOAD_URL: https://downloads.mesosphere.com/dcos-demo/flink/flink-job-1.0.jar FILE: flink-job-1.0.jar JOBMANAGER: flink-demo-flink-jobmanager
fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/community/x86_64/APKINDEX.tar.gz
(1/7) Installing ca-certificates (20190108-r0)
(2/7) Installing nghttp2-libs (1.35.1-r0)
(3/7) Installing libssh2 (1.8.2-r0)
(4/7) Installing libcurl (7.64.0-r2)
(5/7) Installing curl (7.64.0-r2)
(6/7) Installing oniguruma (6.9.1-r0)
(7/7) Installing jq (1.6-r0)
Executing busybox-1.29.3-r10.trigger
Executing ca-certificates-20190108-r0.trigger
OK: 16 MiB in 25 packages
{"filename":"/ha/data/flink-web-upload/1044f898-66b0-4c71-a59c-602cdd53a7b9_flink-job-1.0.jar","status":"success"}Wed Jul 10 18:54:50 UTC 2019
Found jar 1044f898-66b0-4c71-a59c-602cdd53a7b9_flink-job-1.0.jar
RESPONSE: null
SUBMITTED JOB!
```

To get the fraud output from the actor:

```bash
kubectl logs $(kubectl get pod -l actor=flink-demo -o jsonpath="{.items[0].metadata.name}")
```

The output will look like:

```bash
Broker:   flink-demo-kafka-kafka-0.flink-demo-kafka-svc:9093
Topic:   fraud

Detected Fraud:   TransactionAggregate {startTimestamp=0, endTimestamp=1562784331000, totalAmount=11612:
Transaction{timestamp=1562784330000, origin=1, target='5', amount=5175}
Transaction{timestamp=1562784331000, origin=1, target='5', amount=6437}}

Detected Fraud:   TransactionAggregate {startTimestamp=0, endTimestamp=1562784349000, totalAmount=16917:
Transaction{timestamp=1562784339000, origin=0, target='7', amount=9028}
Transaction{timestamp=1562784349000, origin=0, target='7', amount=7889}}
```

Congratulations, you just installed a highly available Flink cluster that runs a financial fraud detection job!

### Clean the state

To successfully uninstall the demo follow those steps:

- Delete the `flink-demo` instance: `kubectl delete instance flink-demo`
- Delete all PVCs:
    - For Kafka: `kubectl delete pvc -l instance=flink-demo-kafka`
    - For Zookeeper: `kubectl delete pvc -l instance=flink-demo-zk`
