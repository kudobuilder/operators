apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Name }}-kafka-connect-config
  namespace: {{ .Namespace }}
data:
  connect-distributed.properties: |
    # This file contains some of the configurations for the Kafka Connect distributed worker. This file is intended
    # to be used with the examples, and some settings may differ from those used in a production system, especially
    # the `bootstrap.servers` and those specifying replication factors.
    
    # A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
    bootstrap.servers={{ if gt (int .Params.BROKER_COUNT) 0 }} {{ .Name }}-kafka-0.{{ .Name }}-svc:{{ .Params.BROKER_PORT }}{{- $root := . -}}{{ range $i, $v := untilStep 1 (int .Params.BROKER_COUNT) 1 }},{{ $root.Name }}-kafka-{{ $v }}.{{ $root.Name }}-svc:{{ $root.Params.BROKER_PORT }}{{ end }}{{ end }}
    
    # unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs
    group.id={{ .Name }}-connect-cluster
    
    # The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
    # need to configure these based on the format they want their data in when loaded from or stored into Kafka
    key.converter={{ .Params.KAFKA_CONNECT_KEY_CONVERTER }}
    value.converter={{ .Params.KAFKA_CONNECT_VALUE_CONVERTER }}
    
    # Topic to use for storing offsets. This topic should have many partitions and be replicated and compacted.
    # Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
    # the topic before starting Kafka Connect if a specific topic configuration is needed.
    # Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
    # Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
    # to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
    offset.storage.topic={{ .Name }}-connect-offsets
    offset.storage.replication.factor={{ if lt (int .Params.BROKER_COUNT) 3 }}{{ .Params.BROKER_COUNT }}{{ else }}3{{ end }}
    #offset.storage.partitions=25
    
    # Topic to use for storing connector and task configurations; note that this should be a single partition, highly replicated,
    # and compacted topic. Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
    # the topic before starting Kafka Connect if a specific topic configuration is needed.
    # Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
    # Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
    # to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
    config.storage.topic={{ .Name }}-connect-configs
    config.storage.replication.factor={{ if lt (int .Params.BROKER_COUNT) 3 }}{{ .Params.BROKER_COUNT }}{{ else }}3{{ end }}
    
    # Topic to use for storing statuses. This topic can have multiple partitions and should be replicated and compacted.
    # Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
    # the topic before starting Kafka Connect if a specific topic configuration is needed.
    # Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
    # Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
    # to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
    status.storage.topic={{ .Name }}-connect-status
    status.storage.replication.factor={{ if lt (int .Params.BROKER_COUNT) 3 }}{{ .Params.BROKER_COUNT }}{{ else }}3{{ end }}
    #status.storage.partitions=1
    
    # Flush much faster than normal, which is useful for testing/debugging
    offset.flush.interval.ms={{ .Params.KAFKA_CONNECT_OFFSET_FLUSH_INTERVAL_MS }}
    
    # These are provided to inform the user about the presence of the REST host and port configs 
    # Hostname & Port for the REST API to listen on. If this is set, it will bind to the interface used to listen to requests.
    #rest.host.name=
    rest.port={{ .Params.KAFKA_CONNECT_REST_PORT }}
    
    # The Hostname & Port that will be given out to other workers to connect to i.e. URLs that are routable from other servers.
    #rest.advertised.host.name=
    #rest.advertised.port=
    
    # Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins
    # (connectors, converters, transformations). The list should consist of top level directories that include 
    # any combination of: 
    # a) directories immediately containing jars with plugins and their dependencies
    # b) uber-jars with plugins and their dependencies
    # c) directories immediately containing the package directory structure of classes of plugins and their dependencies
    # Examples: 
    plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/kafka/connectors,
    #plugin.path=
